{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Facial Expression Detection\n## By Sergei Issaev","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Introduction\nHello everyone! Today I will be using a dataset of human faces, provided by Sulthan Khan (https://www.kaggle.com/sulthankhan/facial-expression-recognition), to build a human expression classifier. Although the dataset is large, the images are relatively small - 48 by 48 pixels, which will make it more difficult to attain a high classification accuracy. Let's get started!","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Import Libraries","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, random_split, DataLoader\nfrom PIL import Image\nimport torchvision.models as models\nfrom tqdm.notebook import tqdm\nimport torchvision.transforms as T\nfrom sklearn.metrics import f1_score\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom torchvision.utils import make_grid\nfrom torchvision.datasets import ImageFolder\nimport PIL\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nnp.random.seed(42)\ntorch.manual_seed(42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load in the Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data augmentation\nimagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n\ntrain_tfms = T.Compose([\n    T.RandomCrop(48, padding=8, padding_mode='reflect'),\n     #T.RandomResizedCrop(256, scale=(0.5,0.9), ratio=(1, 1)), \n    T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n    T.Resize((48, 48)),\n    T.RandomHorizontalFlip(), \n    T.RandomRotation(10),\n    T.ToTensor(), \n     T.Normalize(*imagenet_stats,inplace=True), \n    #T.RandomErasing(inplace=True)\n])\n\nvalid_tfms = T.Compose([\n     T.Resize((48, 48)), \n    T.ToTensor(), \n     T.Normalize(*imagenet_stats)\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndataset = ImageFolder(root='/kaggle/input/facial-expression-recognition/train/')\n\ndataset_size = len(dataset)\ndataset_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testdataset = ImageFolder(root='/kaggle/input/facial-expression-recognition/test/', transform = valid_tfms)\n\ntestdataset_size = len(testdataset)\ntestdataset_size","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### EDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dict = {0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happy', 4: 'neutral', 5: 'sad', 6: 'surprise'}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_image = np.random.randint(0, 28708)\nprint('Random image number ', random_image)\nprint('Class label', dict[dataset[random_image][1]])\ndataset[random_image][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_image = np.random.randint(0, 28708)\nprint('Random image number ', random_image)\nprint('Class label', dict[dataset[random_image][1]])\ndataset[random_image][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_image = np.random.randint(0, 28708)\nprint('Random image number ', random_image)\nprint('Class label', dict[dataset[random_image][1]])\ndataset[random_image][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = dataset.classes\nclasses","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = len(dataset.classes)\nnum_classes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Perform Train-Test Split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"val_size = 1000\ntrain_size = len(dataset) - val_size\n\ntrain_df, val_df = random_split(dataset, [train_size, val_size])\nlen(train_df), len(val_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_df.dataset.transform = valid_tfms\n\ntrain_df.dataset.transform = train_tfms","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\n\ntrain_dl = DataLoader(train_df, batch_size, shuffle=True, \n                      num_workers=3, pin_memory=True)\nval_dl = DataLoader(val_df, batch_size*2, \n                    num_workers=2, pin_memory=True)\ntest_dl = DataLoader(testdataset, batch_size*2, \n                    num_workers=2, pin_memory=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for images, _ in train_dl:\n    print('images.shape:', images.shape)\n    plt.figure(figsize=(16,8))\n    plt.axis('off')\n    plt.imshow(make_grid(images, nrow=16).permute((1, 2, 0)))\n    break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define the Models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CnnModel2(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        # Use a pretrained model\n        self.network = models.wide_resnet101_2(pretrained=True)\n        # Replace last layer\n        num_ftrs = self.network.fc.in_features\n        self.network.fc = nn.Linear(num_ftrs, 7)\n    \n    def forward(self, xb):\n        return torch.sigmoid(self.network(xb))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = get_default_device()\ndevice","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = to_device(CnnModel2(), device)\ntrain_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\ntest_dl = DeviceDataLoader(test_dl, device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for images, labels in train_dl:\n    print('images.shape:', images.shape)\n    out = model(images)\n    print('out.shape:', out.shape)\n    print('out[0]:', out[0])\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n    \ndef fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache()\n    history = []\n    \n    # Set up cutom optimizer with weight decay\n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    # Set up one-cycle learning rate scheduler\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n                                                steps_per_epoch=len(train_loader))\n    \n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        lrs = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            \n            # Gradient clipping\n            if grad_clip: \n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n            \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            # Record & update learning rate\n            lrs.append(get_lr(optimizer))\n            sched.step()\n        \n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train the Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set search to a larger number to test out more hyperparameters\nsearch = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = [evaluate(model, val_dl)]\nhistory","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = np.random.randint(2, 25)\nmax_lr = np.random.choice([5e-2, 1e-3, 5e-3, 1e-4, 5e-4, 1e-5, 5e-5, 1e-6])\ngrad_clip = np.random.choice([0.5, 0.4, 0.3, 0.2, 0.1, 0.05])\nweight_decay = np.random.choice([1e-2, 5e-2, 1e-3, 5e-3, 1e-4, 5e-4, 1e-5])\nopt_func = torch.optim.Adam\nprint('epoch = ', epochs, 'lr = ', max_lr, 'grad is ', grad_clip, 'weights = ', weight_decay)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.cuda.empty_cache()\n\n\nhistory += fit_one_cycle(epochs, max_lr, model, train_dl, val_dl, \n                             grad_clip=grad_clip, \n                             weight_decay=weight_decay, \n                             opt_func=opt_func)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for j in range(search):\n    model = to_device(CnnModel2(), device)\n    history = [evaluate(model, val_dl)]\n    print(history)\n    epochs = np.random.randint(2, 25)\n    max_lr = np.random.choice([5e-2, 1e-3, 5e-3, 1e-4, 5e-4, 1e-5, 5e-5, 1e-6])\n    grad_clip = np.random.choice([0.5, 0.4, 0.3, 0.2, 0.1, 0.05])\n    weight_decay = np.random.choice([1e-2, 5e-2, 1e-3, 5e-3, 1e-4, 5e-4, 1e-5])\n    opt_func = torch.optim.Adam\n    print('epoch = ', epochs, 'lr = ', max_lr, 'grad is ', grad_clip, 'weights = ', weight_decay)\n    torch.cuda.empty_cache()\n\n\n    history += fit_one_cycle(epochs, max_lr, model, train_dl, val_dl, \n                                 grad_clip=grad_clip, \n                                 weight_decay=weight_decay, \n                                 opt_func=opt_func)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for j in range(search):\n    model = to_device(CnnModel2(), device)\n    history = [evaluate(model, val_dl)]\n    print(history)\n    epochs = np.random.randint(12,24)\n    max_lr = np.random.choice([ 5e-3, 1e-4, 5e-4, 1e-5, 5e-5])\n    grad_clip = np.random.choice([0.2, 0.15, 0.1, 0.05])\n    weight_decay = np.random.choice([ 5e-3, 1e-4, 5e-4, 1e-5])\n    opt_func = torch.optim.Adam\n    print('epoch = ', epochs, 'lr = ', max_lr, 'grad is ', grad_clip, 'weights = ', weight_decay)\n    torch.cuda.empty_cache()\n\n\n    history += fit_one_cycle(epochs, max_lr, model, train_dl, val_dl, \n                                 grad_clip=grad_clip, \n                                 weight_decay=weight_decay, \n                                 opt_func=opt_func)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Final Training with best hyperparameters","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = to_device(CnnModel2(), device)\nhistory = [evaluate(model, val_dl)]\nprint(history)\nepochs = 45\nmax_lr = 0.0001\ngrad_clip = 0.025\nweight_decay = 1e-5\nopt_func = torch.optim.Adam\nprint('epoch = ', epochs, 'lr = ', max_lr, 'grad is ', grad_clip, 'weights = ', weight_decay)\ntorch.cuda.empty_cache()\n\n\nhistory += fit_one_cycle(epochs, max_lr, model, train_dl, val_dl, \n                                 grad_clip=grad_clip, \n                                 weight_decay=weight_decay, \n                                 opt_func=opt_func)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');\n\nplot_losses(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');\n\nplot_accuracies(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_lrs(history):\n    lrs = np.concatenate([x.get('lrs', []) for x in history])\n    plt.plot(lrs)\n    plt.xlabel('Batch no.')\n    plt.ylabel('Learning rate')\n    plt.title('Learning Rate vs. Batch no.');\n\nplot_lrs(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Final Results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate(model, val_dl)['val_acc']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate(model, test_dl)['val_acc']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test it out!!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_image(img, model):\n    xb = to_device(img.unsqueeze(0), device)\n    yb = model(xb)\n    _, preds  = torch.max(yb, dim=1)\n    return preds[0].item()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = test_dl[0]\nplt.imshow(img[0], cmap='gray')\nprint('Label:', dataset.classes[label], ', Predicted:', dataset.classes[predict_image(img, model)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thank you for reading, and please upvote if you enjoyed! \n\n![](http://external-preview.redd.it/Ag4b71XcvFY6yk2UZ244G6tLLfPSQxGQhpWQLjXW3Mo.jpg?auto=webp&s=cf9188290fdc98bd5cb4ec35ce7308db944bcf17)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}